"""
ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ëª¨ë“ˆ
ë„¤ì´ë²„ ë‰´ìŠ¤ ì†ë³´ í˜ì´ì§€ì—ì„œ ìƒìœ„ 10ê°œ ê¸°ì‚¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

import requests
from bs4 import BeautifulSoup
from typing import List, Dict


class NaverNewsCrawler:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.base_url = "https://news.naver.com/main/list.naver"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
    
    def get_breaking_news(self, limit: int = 10) -> List[Dict[str, str]]:
        """
        ë„¤ì´ë²„ ì†ë³´ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            limit: ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜ (ê¸°ë³¸ê°’: 10)
        
        Returns:
            ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ì œëª©, URL í¬í•¨)
        """
        params = {
            'mode': 'LSD',
            'mid': 'sec',
            'sid1': '001'  # ì •ì¹˜
        }
        
        try:
            response = requests.get(
                self.base_url,
                params=params,
                headers=self.headers,
                timeout=10
            )
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            news_list = []
            
            # ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
            news_items = soup.select('ul.type06_headline li') + soup.select('ul.type06 li')
            
            for item in news_items[:limit]:
                link_tag = item.select_one('dt:not(.photo) a') or item.select_one('a')
                if link_tag:
                    title = link_tag.get_text(strip=True)
                    url = link_tag.get('href', '')
                    
                    # URLì´ ìƒëŒ€ê²½ë¡œì¸ ê²½ìš° ì ˆëŒ€ê²½ë¡œë¡œ ë³€í™˜
                    if url.startswith('/'):
                        url = 'https://news.naver.com' + url
                    
                    news_list.append({
                        'title': title,
                        'url': url
                    })
                
                if len(news_list) >= limit:
                    break
            
            return news_list
        
        except requests.RequestException as e:
            print(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def format_news_message(self, news_list: List[Dict[str, str]]) -> str:
        """
        ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
        
        Args:
            news_list: ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            í¬ë§·íŒ…ëœ ë©”ì‹œì§€ ë¬¸ìì—´
        """
        if not news_list:
            return "ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        message = "ğŸ“° ì˜¤ëŠ˜ì˜ ë„¤ì´ë²„ ë‰´ìŠ¤ TOP 10\n\n"
        
        for idx, news in enumerate(news_list, 1):
            message += f"{idx}. {news['title']}\n"
            message += f"   ğŸ”— {news['url']}\n\n"
        
        return message.strip()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    crawler = NaverNewsCrawler()
    news = crawler.get_breaking_news(10)
    
    if news:
        print(f"âœ… {len(news)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\n")
        print(crawler.format_news_message(news))
    else:
        print("âŒ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")